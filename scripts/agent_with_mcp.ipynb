{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a_Orwta03znz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fire'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfire\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_stack_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlamaStackClient\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_stack_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fire'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import fire\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client.types.agent_create_params import AgentConfig\n",
    "from termcolor import colored\n",
    "\n",
    "base_url = \"http://localhost:8321\"\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    # base_url=f\"http://{host}:{port}\",\n",
    "    base_url=base_url,\n",
    "    provider_data={\"tavily_search_api_key\": \"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\"},\n",
    ")\n",
    "\n",
    "available_shields = [shield.identifier for shield in client.shields.list()]\n",
    "\n",
    "if not available_shields:\n",
    "    print(colored(\"No available shields. Disabling safety.\", \"yellow\"))\n",
    "else:\n",
    "    print(f\"Available shields found: {available_shields}\")\n",
    "\n",
    "available_models = [\n",
    "    model.identifier for model in client.models.list() if model.model_type == \"llm\"\n",
    "]\n",
    "if not available_models:\n",
    "    print(colored(\"No available models. Exiting.\", \"red\"))\n",
    "    # return\n",
    "else:\n",
    "    selected_model = available_models[0]\n",
    "    print(f\"Using model: {selected_model}\")\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    model=selected_model,\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    sampling_params={\n",
    "        \"strategy\": {\"type\": \"top_p\", \"temperature\": 1.0, \"top_p\": 0.9},\n",
    "    },\n",
    "    toolgroups=(\n",
    "        [\n",
    "            \"mcp::slack\",\n",
    "            #\"builtin::websearch\",\n",
    "            #\"mcp::pdf\",\n",
    "            \"mcp::crm\",\n",
    "            # \"mcp::python\",\n",
    "        ]\n",
    "    ),\n",
    "    tool_choice=\"auto\",\n",
    "    input_shields=available_shields if available_shields else [],\n",
    "    output_shields=available_shields if available_shields else [],\n",
    "    enable_session_persistence=False,\n",
    ")\n",
    "agent = Agent(client, agent_config)\n",
    "\n",
    "user_prompts = [\n",
    "    \"Review the current opportunities for ACME\",\n",
    "    \"Post a slack message in the agentic-ai-slack channel with the opportunities\",\n",
    "    \"Get a list of support cases for the account\",\n",
    "    \"Post a slack message in the agentic-ai-slack channel with the list of support cases\",\n",
    "    \"Determine the status of the account, e.g. unhappy, happy etc. based on the cases\",\n",
    "    \"Post a slack message in the agentic-ai-slack channel with the status of the account\",\n",
    "]\n",
    "\n",
    "session_id = agent.create_session(\"test-session\")\n",
    "\n",
    "for prompt in user_prompts:\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "    )\n",
    "\n",
    "    for log in EventLogger().log(response):\n",
    "        log.print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
