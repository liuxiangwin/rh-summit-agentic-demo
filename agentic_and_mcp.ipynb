{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Agentic & MCP Demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a6454",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Pre-Requisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- A running Llama Stack server with the mcp::crm toolgroup configured\n",
    "\n",
    "### Installing dependencies\n",
    "\n",
    "This code requires `llama-stack` and the `llama-stack-client`, both at version `0.2.2`. Lets begin by installing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4481ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-stack-client==0.2.2\n",
      "  Downloading llama_stack_client-0.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting llama-stack==0.2.2\n",
      "  Downloading llama_stack-0.2.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (4.6.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (0.27.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: prompt-toolkit in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (3.0.50)\n",
      "Collecting pyaml (from llama-stack-client==0.2.2)\n",
      "  Using cached pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (2.9.2)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (13.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (1.3.1)\n",
      "Collecting termcolor (from llama-stack-client==0.2.2)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack-client==0.2.2) (4.12.2)\n",
      "Collecting blobfile (from llama-stack==0.2.2)\n",
      "  Using cached blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fire (from llama-stack==0.2.2)\n",
      "  Using cached fire-0.7.0.tar.gz (87 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (0.26.2)\n",
      "Collecting jinja2>=3.1.6 (from llama-stack==0.2.2)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (4.23.0)\n",
      "Collecting openai>=1.66 (from llama-stack==0.2.2)\n",
      "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (1.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (65.5.0)\n",
      "Collecting tiktoken (from llama-stack==0.2.2)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-stack==0.2.2) (10.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->llama-stack-client==0.2.2) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.2.2) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.2.2) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama-stack-client==0.2.2) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2>=3.1.6->llama-stack==0.2.2) (2.1.5)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.66->llama-stack==0.2.2) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->llama-stack-client==0.2.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->llama-stack-client==0.2.2) (2.23.4)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile->llama-stack==0.2.2)\n",
      "  Using cached pycryptodomex-3.22.0-cp37-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from blobfile->llama-stack==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: lxml>=4.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from blobfile->llama-stack==0.2.2) (5.3.0)\n",
      "Requirement already satisfied: filelock>=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from blobfile->llama-stack==0.2.2) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->llama-stack==0.2.2) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->llama-stack==0.2.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->llama-stack==0.2.2) (6.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->llama-stack==0.2.2) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->llama-stack==0.2.2) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->llama-stack==0.2.2) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->llama-stack==0.2.2) (0.22.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-stack-client==0.2.2) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-stack-client==0.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-stack-client==0.2.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-stack-client==0.2.2) (2024.2)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt-toolkit->llama-stack-client==0.2.2) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->llama-stack==0.2.2) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->llama-stack-client==0.2.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->llama-stack-client==0.2.2) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken->llama-stack==0.2.2) (2024.11.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack-client==0.2.2) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client==0.2.2) (1.16.0)\n",
      "Downloading llama_stack_client-0.2.2-py3-none-any.whl (273 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.3/273.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_stack-0.2.2-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Using cached pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached pycryptodomex-3.22.0-cp37-abi3-macosx_10_9_universal2.whl (2.5 MB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114331 sha256=3ec18ae6021a7dff263afce13d8498c5ecd867093867e1c1aca1e9648fbfb083\n",
      "  Stored in directory: /Users/phayes/Library/Caches/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
      "Successfully built fire\n",
      "Installing collected packages: termcolor, pycryptodomex, pyaml, jinja2, tiktoken, fire, blobfile, openai, llama-stack-client, llama-stack\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.51.2\n",
      "    Uninstalling openai-1.51.2:\n",
      "      Successfully uninstalled openai-1.51.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "instructor 0.6.8 requires typer<0.10.0,>=0.9.0, but you have typer 0.12.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blobfile-3.0.0 fire-0.7.0 jinja2-3.1.6 llama-stack-0.2.2 llama-stack-client-0.2.2 openai-1.75.0 pyaml-25.1.0 pycryptodomex-3.22.0 termcolor-3.0.1 tiktoken-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install llama-stack-client==0.2.2 llama-stack==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee3cb2",
   "metadata": {},
   "source": [
    "### Configuring logging\n",
    "\n",
    "Now that we have our dependencies, lets setup logging for the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fc0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "if not logger.hasHandlers():  \n",
    "    logger.setLevel(logging.INFO)\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681412e1",
   "metadata": {},
   "source": [
    "### Connecting to llama-stack server\n",
    "\n",
    "For the llama-stack instance, you can either run it locally or connect to a remote llama-stack instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa38ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server @ http://localhost:5001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from utils import get_any_available_model\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "base_url = os.getenv(\"REMOTE_BASE_URL\", \"http://localhost:5001\")\n",
    "\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url\n",
    ")\n",
    "model = get_any_available_model(client)\n",
    "    \n",
    "logger.info(f\"Connected to Llama Stack server @ {base_url} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "### Validate tools are available in our llama-stack instance\n",
    "\n",
    "When an instance of llama-stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama-stack instance, if you try to register one with the same `toolgroup_id`, llama-stack will throw you an error.\n",
    "\n",
    "For this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that both the `builtin::websearch` and the `mcp::openshift` tools are registered as tools, but if the `mcp::openshift` tool is not listed there, it will attempt to register it using the mcp url.\n",
    "\n",
    "If you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`.\n",
    "\n",
    "If you are running the MCP server from a container, the default value for this is: `http://host.containers.internal:8000/sse`.\n",
    "\n",
    "Make sure to pass the corresponding MCP URL for the server you are trying to register/validate tools for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is already registered with the following tool groups @ {'mcp::crm', 'builtin::rag', 'builtin::websearch', 'builtin::code_interpreter', 'mcp::orders-service'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [t.toolgroup_id for t in registered_tools]\n",
    "logger.info(f\"Your Llama Stack server is already registered with the following tool groups @ {set(registered_toolgroups)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5cbe2",
   "metadata": {},
   "source": [
    "## Get active opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70ace-b704-4379-aa88-3c793cc4f959",
   "metadata": {},
   "source": [
    "### System Prompts for different models\n",
    "\n",
    "**Note:** If you have multiple models configured with your Llama Stack server, you can choose which one to run your queries against. When switching to a different model, you may need to adjust the system prompt to align with that model’s expected behavior. Many models provide recommended system prompts for optimal and reliable outputs—these are typically documented on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374328a3-8c4d-4eb0-9c9d-73e40a9e74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up with which works well for this query\n",
    "\n",
    "sys_prompt1= \"\"\"You are a helpful assistant. Use tools to answer. When you use a tool always respond with a summary of the result.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b46bee8b-a46c-4b97-8273-dda75237d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getOpportunities Args:{'id': '1'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getOpportunities Response:{\"type\":\"text\",\"text\":\"Active Opportunities: [\\n  {\\n    \\\"opportunity_id\\\": 1,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 1,\\n    \\\"account_name\\\": \\\"Acme Corp\\\",\\n    \\\"item_id\\\": 2,\\n    \\\"description\\\": \\\"Upsell - Cloud package\\\",\\n    \\\"amount\\\": \\\"5000.00\\\",\\n    \\\"year\\\": 2025\\n  },\\n  {\\n    \\\"opportunity_id\\\": 1,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 1,\\n    \\\"account_name\\\": \\\"Acme Corp\\\",\\n    \\\"item_id\\\": 1,\\n    \\\"description\\\": \\\"Subscription renewal - Tier A\\\",\\n    \\\"amount\\\": \\\"15000.00\\\",\\n    \\\"year\\\": 2025\\n  },\\n  {\\n    \\\"opportunity_id\\\": 2,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 2,\\n    \\\"account_name\\\": \\\"Globex Inc\\\",\\n    \\\"item_id\\\": 3,\\n    \\\"description\\\": \\\"Enterprise license renewal\\\",\\n    \\\"amount\\\": \\\"25000.00\\\",\\n    \\\"year\\\": 2025\\n  }\\n]\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m function\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mget\u001b[0m\u001b[33mOp\u001b[0m\u001b[33mport\u001b[0m\u001b[33munities\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m returned\u001b[0m\u001b[33m a\u001b[0m\u001b[33m list\u001b[0m\u001b[33m of\u001b[0m\u001b[33m one\u001b[0m\u001b[33m active\u001b[0m\u001b[33m opportunity\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m opportunity\u001b[0m\u001b[33m details\u001b[0m\u001b[33m are\u001b[0m\u001b[33m as\u001b[0m\u001b[33m follows\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Opportunity\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Status\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Active\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ac\u001b[0m\u001b[33mme\u001b[0m\u001b[33m Corp\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Item\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m2\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Description\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ups\u001b[0m\u001b[33mell\u001b[0m\u001b[33m -\u001b[0m\u001b[33m Cloud\u001b[0m\u001b[33m package\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Amount\u001b[0m\u001b[33m:\u001b[0m\u001b[33m $\u001b[0m\u001b[33m500\u001b[0m\u001b[33m0\u001b[0m\u001b[33m.\u001b[0m\u001b[33m00\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Year\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m202\u001b[0m\u001b[33m5\u001b[0m\u001b[33m\n",
      "\n",
      "\u001b[0m\u001b[33mThere\u001b[0m\u001b[33m is\u001b[0m\u001b[33m also\u001b[0m\u001b[33m another\u001b[0m\u001b[33m active\u001b[0m\u001b[33m opportunity\u001b[0m\u001b[33m with\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m \u001b[0m\u001b[33m2\u001b[0m\u001b[33m,\u001b[0m\u001b[33m but\u001b[0m\u001b[33m the\u001b[0m\u001b[33m details\u001b[0m\u001b[33m are\u001b[0m\u001b[33m not\u001b[0m\u001b[33m provided\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m output\u001b[0m\u001b[33m.\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import Agent\n",
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model, # replace this with your choice of model\n",
    "    instructions = sys_prompt1 , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::crm\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"}\n",
    ")\n",
    "\n",
    "user_prompts = [\"Get one active opportunities\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_demo\")\n",
    "\n",
    "for prompt in user_prompts:\n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e857dcc-6e78-42b7-96c3-4a3d32d59b4d",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the pods_run tool configured with the OpenShift MCP server, to run the pod with the requested docker image in the OpenShift cluster.\n",
    "2. The tool successfully executes and creates the pod.\n",
    "3. The LLM recieves the response from the tool call, results of the pod manifest created, along with the original query.\n",
    "4. Finally, this context gets passed back to the LLM for the final inference. The inference result starts by responding to my initial question with some background, and then finally providing details about the pod specifications and configurations created as well mentionining that the pod might be in pending state indicating that it might take few minutes to successfully complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9830e45-5633-4eb3-9270-643a27e24f2a",
   "metadata": {},
   "source": [
    "## Analyse account sentiment for active opportunities\n",
    "\n",
    "Get a list of active opportunities, then find the associated support cases for each opportunity, then anayse the mood of the account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd82e55-17df-4979-86ef-22e35a186c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up with which works well for this query\n",
    "sys_prompt2=\"\"\"You are a helpful AI assistant, responsible for helping me find and communicate information back to my team.\n",
    "    You have access to a number of tools.\n",
    "    Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\n",
    "    When you are asked to find out about opportunities and accounts you must use a tool.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe55883a-6887-43dd-9498-5333a51799e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========= Turn: 0 =========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getOpportunities Args:{'id': '1'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getOpportunities Response:{\"type\":\"text\",\"text\":\"Active Opportunities: [\\n  {\\n    \\\"opportunity_id\\\": 1,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 1,\\n    \\\"account_name\\\": \\\"Acme Corp\\\",\\n    \\\"item_id\\\": 2,\\n    \\\"description\\\": \\\"Upsell - Cloud package\\\",\\n    \\\"amount\\\": \\\"5000.00\\\",\\n    \\\"year\\\": 2025\\n  },\\n  {\\n    \\\"opportunity_id\\\": 1,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 1,\\n    \\\"account_name\\\": \\\"Acme Corp\\\",\\n    \\\"item_id\\\": 1,\\n    \\\"description\\\": \\\"Subscription renewal - Tier A\\\",\\n    \\\"amount\\\": \\\"15000.00\\\",\\n    \\\"year\\\": 2025\\n  },\\n  {\\n    \\\"opportunity_id\\\": 2,\\n    \\\"status\\\": \\\"active\\\",\\n    \\\"account_id\\\": 2,\\n    \\\"account_name\\\": \\\"Globex Inc\\\",\\n    \\\"item_id\\\": 3,\\n    \\\"description\\\": \\\"Enterprise license renewal\\\",\\n    \\\"amount\\\": \\\"25000.00\\\",\\n    \\\"year\\\": 2025\\n  }\\n]\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m active\u001b[0m\u001b[33m opportunity\u001b[0m\u001b[33m is\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Opportunity\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Status\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Active\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ac\u001b[0m\u001b[33mme\u001b[0m\u001b[33m Corp\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Item\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m2\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Description\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ups\u001b[0m\u001b[33mell\u001b[0m\u001b[33m -\u001b[0m\u001b[33m Cloud\u001b[0m\u001b[33m package\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Amount\u001b[0m\u001b[33m:\u001b[0m\u001b[33m $\u001b[0m\u001b[33m500\u001b[0m\u001b[33m0\u001b[0m\u001b[33m.\u001b[0m\u001b[33m00\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Year\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m202\u001b[0m\u001b[33m5\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========= Turn: 1 =========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getSupportCases Args:{'id': '1'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:getSupportCases Response:{\"type\":\"text\",\"text\":\"Support Cases for account 1:[\\n  {\\n    \\\"case_id\\\": 1,\\n    \\\"subject\\\": \\\"Login failure\\\",\\n    \\\"description\\\": \\\"Customer unable to log in with correct credentials.\\\",\\n    \\\"status\\\": \\\"open\\\",\\n    \\\"severity\\\": \\\"High\\\",\\n    \\\"created_at\\\": \\\"2025-04-16T22:57:50.901Z\\\",\\n    \\\"account_name\\\": \\\"Acme Corp\\\"\\n  },\\n  {\\n    \\\"case_id\\\": 2,\\n    \\\"subject\\\": \\\"Slow dashboard\\\",\\n    \\\"description\\\": \\\"Performance issues loading analytics dashboard.\\\",\\n    \\\"status\\\": \\\"in progress\\\",\\n    \\\"severity\\\": \\\"Critical\\\",\\n    \\\"created_at\\\": \\\"2025-04-16T22:57:50.901Z\\\",\\n    \\\"account_name\\\": \\\"Acme Corp\\\"\\n  },\\n  {\\n    \\\"case_id\\\": 6,\\n    \\\"subject\\\": \\\"Feature request: Dark mode\\\",\\n    \\\"description\\\": \\\"Request to implement dark mode UI.\\\",\\n    \\\"status\\\": \\\"closed\\\",\\n    \\\"severity\\\": \\\"Low\\\",\\n    \\\"created_at\\\": \\\"2025-04-16T22:57:50.901Z\\\",\\n    \\\"account_name\\\": \\\"Acme Corp\\\"\\n  }\\n]\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m support\u001b[0m\u001b[33m cases\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m associated\u001b[0m\u001b[33m account\u001b[0m\u001b[33m are\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m1\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Case\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Subject\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Login\u001b[0m\u001b[33m failure\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Description\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Customer\u001b[0m\u001b[33m unable\u001b[0m\u001b[33m to\u001b[0m\u001b[33m log\u001b[0m\u001b[33m in\u001b[0m\u001b[33m with\u001b[0m\u001b[33m correct\u001b[0m\u001b[33m credentials\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Status\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Open\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Severity\u001b[0m\u001b[33m:\u001b[0m\u001b[33m High\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Created\u001b[0m\u001b[33m at\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m202\u001b[0m\u001b[33m5\u001b[0m\u001b[33m-\u001b[0m\u001b[33m04\u001b[0m\u001b[33m-\u001b[0m\u001b[33m16\u001b[0m\u001b[33mT\u001b[0m\u001b[33m22\u001b[0m\u001b[33m:\u001b[0m\u001b[33m57\u001b[0m\u001b[33m:\u001b[0m\u001b[33m50\u001b[0m\u001b[33m.\u001b[0m\u001b[33m901\u001b[0m\u001b[33mZ\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ac\u001b[0m\u001b[33mme\u001b[0m\u001b[33m Corp\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m2\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Case\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m2\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Subject\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Slow\u001b[0m\u001b[33m dashboard\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Description\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Performance\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m loading\u001b[0m\u001b[33m analytics\u001b[0m\u001b[33m dashboard\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Status\u001b[0m\u001b[33m:\u001b[0m\u001b[33m In\u001b[0m\u001b[33m Progress\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Severity\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Critical\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Created\u001b[0m\u001b[33m at\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m202\u001b[0m\u001b[33m5\u001b[0m\u001b[33m-\u001b[0m\u001b[33m04\u001b[0m\u001b[33m-\u001b[0m\u001b[33m16\u001b[0m\u001b[33mT\u001b[0m\u001b[33m22\u001b[0m\u001b[33m:\u001b[0m\u001b[33m57\u001b[0m\u001b[33m:\u001b[0m\u001b[33m50\u001b[0m\u001b[33m.\u001b[0m\u001b[33m901\u001b[0m\u001b[33mZ\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ac\u001b[0m\u001b[33mme\u001b[0m\u001b[33m Corp\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m3\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Case\u001b[0m\u001b[33m ID\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m6\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Subject\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Feature\u001b[0m\u001b[33m request\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Dark\u001b[0m\u001b[33m mode\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Description\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Request\u001b[0m\u001b[33m to\u001b[0m\u001b[33m implement\u001b[0m\u001b[33m dark\u001b[0m\u001b[33m mode\u001b[0m\u001b[33m UI\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Status\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Closed\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Severity\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Low\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Created\u001b[0m\u001b[33m at\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m202\u001b[0m\u001b[33m5\u001b[0m\u001b[33m-\u001b[0m\u001b[33m04\u001b[0m\u001b[33m-\u001b[0m\u001b[33m16\u001b[0m\u001b[33mT\u001b[0m\u001b[33m22\u001b[0m\u001b[33m:\u001b[0m\u001b[33m57\u001b[0m\u001b[33m:\u001b[0m\u001b[33m50\u001b[0m\u001b[33m.\u001b[0m\u001b[33m901\u001b[0m\u001b[33mZ\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\t\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Account\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ac\u001b[0m\u001b[33mme\u001b[0m\u001b[33m Corp\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========= Turn: 2 =========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[33mBased\u001b[0m\u001b[33m on\u001b[0m\u001b[33m the\u001b[0m\u001b[33m support\u001b[0m\u001b[33m cases\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m can\u001b[0m\u001b[33m analyze\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m's\u001b[0m\u001b[33m satisfaction\u001b[0m\u001b[33m level\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Here\u001b[0m\u001b[33m's\u001b[0m\u001b[33m my\u001b[0m\u001b[33m assessment\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m1\u001b[0m\u001b[33m.\u001b[0m\u001b[33m **\u001b[0m\u001b[33mLogin\u001b[0m\u001b[33m failure\u001b[0m\u001b[33m**:\u001b[0m\u001b[33m The\u001b[0m\u001b[33m customer\u001b[0m\u001b[33m is\u001b[0m\u001b[33m unable\u001b[0m\u001b[33m to\u001b[0m\u001b[33m log\u001b[0m\u001b[33m in\u001b[0m\u001b[33m with\u001b[0m\u001b[33m correct\u001b[0m\u001b[33m credentials\u001b[0m\u001b[33m,\u001b[0m\u001b[33m which\u001b[0m\u001b[33m indicates\u001b[0m\u001b[33m a\u001b[0m\u001b[33m significant\u001b[0m\u001b[33m issue\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m's\u001b[0m\u001b[33m functionality\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m suggests\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m is\u001b[0m\u001b[33m not\u001b[0m\u001b[33m satisfied\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m current\u001b[0m\u001b[33m state\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m2\u001b[0m\u001b[33m.\u001b[0m\u001b[33m **\u001b[0m\u001b[33mSlow\u001b[0m\u001b[33m dashboard\u001b[0m\u001b[33m**:\u001b[0m\u001b[33m The\u001b[0m\u001b[33m performance\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m loading\u001b[0m\u001b[33m the\u001b[0m\u001b[33m analytics\u001b[0m\u001b[33m dashboard\u001b[0m\u001b[33m indicate\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m is\u001b[0m\u001b[33m experiencing\u001b[0m\u001b[33m technical\u001b[0m\u001b[33m difficulties\u001b[0m\u001b[33m,\u001b[0m\u001b[33m which\u001b[0m\u001b[33m can\u001b[0m\u001b[33m be\u001b[0m\u001b[33m frustrating\u001b[0m\u001b[33m and\u001b[0m\u001b[33m impact\u001b[0m\u001b[33m their\u001b[0m\u001b[33m ability\u001b[0m\u001b[33m to\u001b[0m\u001b[33m use\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m effectively\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m3\u001b[0m\u001b[33m.\u001b[0m\u001b[33m **\u001b[0m\u001b[33mFeature\u001b[0m\u001b[33m request\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Dark\u001b[0m\u001b[33m mode\u001b[0m\u001b[33m**:\u001b[0m\u001b[33m While\u001b[0m\u001b[33m this\u001b[0m\u001b[33m case\u001b[0m\u001b[33m is\u001b[0m\u001b[33m closed\u001b[0m\u001b[33m,\u001b[0m\u001b[33m it\u001b[0m\u001b[33m suggests\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m is\u001b[0m\u001b[33m interested\u001b[0m\u001b[33m in\u001b[0m\u001b[33m seeing\u001b[0m\u001b[33m improvements\u001b[0m\u001b[33m to\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m,\u001b[0m\u001b[33m specifically\u001b[0m\u001b[33m in\u001b[0m\u001b[33m terms\u001b[0m\u001b[33m of\u001b[0m\u001b[33m user\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m indicates\u001b[0m\u001b[33m a\u001b[0m\u001b[33m level\u001b[0m\u001b[33m of\u001b[0m\u001b[33m dissatisfaction\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m current\u001b[0m\u001b[33m state\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m.\n",
      "\n",
      "\u001b[0m\u001b[33mOverall\u001b[0m\u001b[33m,\u001b[0m\u001b[33m based\u001b[0m\u001b[33m on\u001b[0m\u001b[33m these\u001b[0m\u001b[33m support\u001b[0m\u001b[33m cases\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m would\u001b[0m\u001b[33m rate\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m's\u001b[0m\u001b[33m satisfaction\u001b[0m\u001b[33m level\u001b[0m\u001b[33m as\u001b[0m\u001b[33m **\u001b[0m\u001b[33mUn\u001b[0m\u001b[33mhappy\u001b[0m\u001b[33m**\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m account\u001b[0m\u001b[33m is\u001b[0m\u001b[33m experiencing\u001b[0m\u001b[33m significant\u001b[0m\u001b[33m technical\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m and\u001b[0m\u001b[33m is\u001b[0m\u001b[33m interested\u001b[0m\u001b[33m in\u001b[0m\u001b[33m seeing\u001b[0m\u001b[33m improvements\u001b[0m\u001b[33m to\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m.\u001b[0m\u001b[33m These\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m are\u001b[0m\u001b[33m likely\u001b[0m\u001b[33m to\u001b[0m\u001b[33m impact\u001b[0m\u001b[33m their\u001b[0m\u001b[33m overall\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m and\u001b[0m\u001b[33m satisfaction\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m.\n",
      "\n",
      "\u001b[0m\u001b[33mRecommend\u001b[0m\u001b[33mation\u001b[0m\u001b[33m:\u001b[0m\u001b[33m I\u001b[0m\u001b[33m would\u001b[0m\u001b[33m recommend\u001b[0m\u001b[33m priorit\u001b[0m\u001b[33mizing\u001b[0m\u001b[33m the\u001b[0m\u001b[33m resolution\u001b[0m\u001b[33m of\u001b[0m\u001b[33m these\u001b[0m\u001b[33m technical\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m and\u001b[0m\u001b[33m exploring\u001b[0m\u001b[33m ways\u001b[0m\u001b[33m to\u001b[0m\u001b[33m improve\u001b[0m\u001b[33m the\u001b[0m\u001b[33m user\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m,\u001b[0m\u001b[33m such\u001b[0m\u001b[33m as\u001b[0m\u001b[33m implementing\u001b[0m\u001b[33m dark\u001b[0m\u001b[33m mode\u001b[0m\u001b[33m or\u001b[0m\u001b[33m enhancing\u001b[0m\u001b[33m performance\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m will\u001b[0m\u001b[33m help\u001b[0m\u001b[33m to\u001b[0m\u001b[33m increase\u001b[0m\u001b[33m the\u001b[0m\u001b[33m account\u001b[0m\u001b[33m's\u001b[0m\u001b[33m satisfaction\u001b[0m\u001b[33m level\u001b[0m\u001b[33m and\u001b[0m\u001b[33m improve\u001b[0m\u001b[33m their\u001b[0m\u001b[33m overall\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m service\u001b[0m\u001b[33m.\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    instructions=sys_prompt2,\n",
    "    tools=[\"mcp::crm\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params={\n",
    "        \"max_tokens\":4096,\n",
    "        \"strategy\": {\"type\": \"greedy\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "session_id = agent.create_session(session_name=\"Draft_email_with_latest_OCP_version\")\n",
    "\n",
    "prompts = [\n",
    "    \"\"\"Get one active opportunity\"\"\",\n",
    "    \"\"\"get a list of support cases for the associated account\"\"\",\n",
    "    \"\"\"Analyse the support cases and determine how happy the account is\"\"\",\n",
    "\n",
    "]\n",
    "for i, prompt in enumerate(prompts):    \n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    logger.info(f\"========= Turn: {i} =========\")\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81fb87-19cd-4755-96d5-59628cc75daf",
   "metadata": {},
   "source": [
    "#### Output Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbc8ab-77c6-48ff-970c-2d5dfd54a2c7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This tutorial demonstrates how to build agentic MCP applications with Llama Stack. We do so by initializing an agent while giving it access to the MCP tools configured with Llama Stack, then invoking the agent on each of the specified queries. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
